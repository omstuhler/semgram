#' Extraction function
#'
#' This function extracts motifs from text.
#'
#' @param tokens A tokens dataframe with predicted dependencies as generated by spacyr::spacy_parse(). Dependencies need to be in ClearNLP style. This tag set is used by all English language models implemented in spaCy. Other languages or dependency grammars are currently not supported.
#' @param entities Specifies the core entities around which to extract motifs.
#' This can be a single character string or a vector of character strings.
#' Multi-token strings such as "Harry Potter" will be parsed if parse_multi_token_entities is set to TRUE. Note that this parameter is case-sensitive.
#' @param motif_classes A character vector specifying which motif classes should be considered in the extraction.
#' This can include "A" for agents, "t" for treatments, "a" for actions, "P" for patients,
#' "be" for characterizations, "H" for possessions, as well as "At" and "aP" for agent-treatment and action-patient motifs respectively.
#' By default, all motif classes are considered. Note, however, that run time increases with the number of motif classes considered.
#' @param fast If set to true, some of the more specific extraction rules are not applied. This results in fewer extractions but faster run time. Defaults to FALSE.
#' @param parse_multi_token_entities Should we multi-token entities (e.g. "Harry Potter') be considered. Defaults to TRUE.
#' @param extract Parameter defines whether we extract the "lemma" or the "token" of a motif. Defaults to "lemma" which reduces sparsity and is preferable for most purposes.
#' @param markup If TRUE, motifs will be marked up according to their motif class. For instance, the action motif "sing" is extracted as "a_sing". Defaults to TRUE.
#' @param be_entity Should things that are linked to an entity via "being" (or one of it's lemmas) be considered as characterization motifs?
#' For example, say we are extracting characterization motifs around the entity "immigrants" in the sentence "my parents are immigrants", should we extract the characterization motif "be_parent"? Defaults to TRUE.
#' @param get_aux_verbs Should auxiliary verbs (e.g. can, could, may, must, etc.) be collected as actions? Defaults to FALSE.
#' @param aux_verb_markup Should auxiliary verbs with "to" be marked up so that "going" in "going to eat" becomes "going-to".
#' Note that this will not affect cases of the sort "going to the bar." This can be especially useful for analyses concerning modality.
#' The parameter defaults to TRUE.
#' @param pron_as_ap Should pronouns be considered as agents and patients? Defaults to FALSE.
#' @param use_appos Should things linked to an entity via an appositional modifier be considered as equivalent to the entity.
#' For example, if we specify our entity to be "Peter" in the sentence "My brother Peter left.", should "brother" be considered equivalent to "Peter"?
#' Only if use_appos = TRUE, we can extract "leaving" as action motif associated with Peter, as the subject associated with "leaving" is "brother".
#' @param lowercase Should tokens and lemmas be lowercased? Defaults to FALSE.
#' @param verbose Defaults to FALSE.
#' @return A list of length eight, one element for each motif class. List element of motif classes not specified in the motif_classes parameter will be empty.
#' @export

extract_motifs = function(tokens = NULL,
                          entities = NULL,
                          motif_classes = c("A","t", "a", "P", "be", "H", "At", "aP"),
                          fast = F,
                          parse_multi_token_entities = T,
                          extract = "lemma",
                          markup = T,
                          be_entity = T,
                          get_aux_verbs = F,
                          aux_verb_markup = T,
                          pron_as_ap = F,
                          use_appos = T,
                          lowercase = F,
                          verbose = F){


  ###############################################################################################
  #####################################Pre-processing############################################
  ###############################################################################################

  ###############################################################################################
  ##### Text input
  if(!exists("tokens")){
    message("It seems you didn't provide a tokens object.\n")
  }
  if(!exists("entities")){
    message("It seems you didn't specify any core entities to extract motifs around.\n")
  }

  ###############################################################################################
  ##### Unify column labels in tokens dataframe
  if("sentence_id" %in% names(tokens)){
    names(tokens)[which(names(tokens) == "sentence_id")] = "sentence"
  }
  if("dep_rel" %in% names(tokens)){
    names(tokens)[which(names(tokens) == "dep_rel")] = "relation"
  }

  ###############################################################################################
  ##### Replace

  # Get all instances of entities that are multigrams
  if(T %in% str_detect(entities, " ") & parse_multi_token_entities == T){
    for(entity in entities){
      if(entity == entities[1]){
        phrase_df = data.frame()
        master_length = dim(tokens)[1]
      }

      entity_split = unlist(spacy_parse(entity)$token)
      entity_length = length(entity_split)

      if(entity_length>1){
        if(verbose){cat("Replacing phrase: ", entity, "\n")}
        length_seq = 1:entity_length
        which_first_id = which(tokens[,"token"] == entity_split[1])

        for(rownumber in which_first_id-1){
          if(isTRUE(all.equal(unname(unlist(tokens[c(rownumber+length_seq), "lemma"])), entity_split))){
            for(token in length_seq){
              row_index = c(rownumber+token)
              if(nrow(phrase_df) == 0){
                phrase_df = rbind(phrase_df, c(tokens[row_index,],
                                               phrase_replacement = paste(entity_split, collapse = " ")),
                                  stringsAsFactors = F)
              } else {
                if(!paste(tokens[row_index,][,c("doc_id", "sentence","token_id")], collapse = "_") %in%
                   str_c(phrase_df$doc_id, phrase_df$sentence, phrase_df$token_id, sep = "_")){
                  phrase_df = rbind(phrase_df, c(tokens[row_index,],
                                                 phrase_replacement = paste(entity_split, collapse = " ")),
                                    stringsAsFactors = F)
                }
              }
            }
          }
        }
      }
    }

    # Merge in the phrase replacements
    if(exists("phrase_df") & nrow(phrase_df) > 0){
      tokens = left_join(tokens, phrase_df[,c("doc_id", "sentence", "token_id", "phrase_replacement")],
                         by = c("doc_id" = "doc_id",
                                "sentence" = "sentence",
                                "token_id" = "token_id"),
                         keep = F)

      tokens$token = ifelse(!is.na(tokens$phrase_replacement), tokens$phrase_replacement, tokens$token)
      #tokens = unique(tokens)
    } else {
      tokens$phrase_replacement = NA
    }
  } else {
    tokens$phrase_replacement = NA
  }
  if(T %in% str_detect(entities, " ") & parse_multi_token_entities == F){
    message("Warning: multi-token entities were detected but parsing them was set to FALSE.\n")
  }


  ###############################################################################################
  ##### Mark up tokens with eligible appos children
  if(use_appos){
    appos_child = tquery(token = entities, relation = "appos",
                         parents(pos = c("NOUN", "PROPN", "PRON"), NOT(token = entities),
                                 label = "appos_child", fill = F
                         )
    )

    tokens = tokens %>%
      annotate_tqueries("appos_child", appos_child, overwrite = T, copy = F)
    tokens[,c(ncol(tokens)-1,ncol(tokens))] = NULL
    } else {
      tokens$appos_child = ""
  }


  ###############################################################################################
  ##### Set pronoun parameter
  if(pron_as_ap){
    agent_patient_pos = c("NOUN", "PROPN", "PRON")
    tokens$lemma = ifelse(tokens$lemma == "-PRON-", tokens$token, tokens$lemma)
    } else {
      agent_patient_pos = c("NOUN", "PROPN")
  }

  ###############################################################################################
  ##### Replace auxiliary phrases

  # Get going to, need to, etc. instances
  if(aux_verb_markup){
    if(verbose){cat("Replacing aux phrases.. ", "\n")}
    aux_phrases = list(c("going", "to"),
                       c("need", "to"), c("needed", "to"),
                       c("have", "to"), c("had", "to"),
                       c("ought", "to"))

    for(aux_phrase in 1:length(aux_phrases)){
      if(aux_phrase == 1){
        aux_phrase_df = data.frame()
        master_length = dim(tokens)[1]
      }

      aux_phrase_split = aux_phrases[[aux_phrase]]

      length_seq = 1:2
      which_first_id = which(tokens[,"token"] == aux_phrase_split[1])

      for(rownumber in which_first_id-1){
        if(isTRUE(all.equal(unname(unlist(tokens[c(rownumber+length_seq), "token"])), aux_phrase_split)) &
           tokens[rownumber+length_seq[2], "relation"] == "aux"){
          for(token in length_seq){
            row_index = c(rownumber+token)
            if(nrow(aux_phrase_df) == 0){
              aux_phrase_df = rbind(aux_phrase_df, c(tokens[row_index,],
                                                     aux_phrase_replacement = paste(aux_phrase_split, collapse = "-")),
                                stringsAsFactors = F)
            } else {
              if(!paste(tokens[row_index,][,c("doc_id", "sentence","token_id")], collapse = "_") %in%
                 str_c(aux_phrase_df$doc_id, aux_phrase_df$sentence, aux_phrase_df$token_id, sep = "_")){
                aux_phrase_df = rbind(aux_phrase_df, c(tokens[row_index,],
                                               aux_phrase_replacement = paste(aux_phrase_split, collapse = "-")),
                                  stringsAsFactors = F)
              }
            }
          }
        }
      }
    }

    # Merge in the phrase replacements
    if(exists("aux_phrase_df") & nrow(aux_phrase_df) > 0){
      tokens = left_join(tokens, aux_phrase_df[,c("doc_id", "sentence", "token_id", "aux_phrase_replacement")],
                         by = c("doc_id" = "doc_id",
                                "sentence" = "sentence",
                                "token_id" = "token_id"),
                         keep = F)

      tokens$token = ifelse(!is.na(tokens$aux_phrase_replacement), tokens$aux_phrase_replacement, tokens$token)
      tokens$lemma = ifelse(!is.na(tokens$aux_phrase_replacement), tokens$aux_phrase_replacement, tokens$lemma)
    } else {
      tokens$aux_phrase_replacement = ""
    }
  } else {
    tokens$aux_phrase_replacement = ""
  }

  ###############################################################################################
  ##### Set auxiliary markup parameter
  if(get_aux_verbs){
    if(!aux_verb_markup){
      message("You are extracting auxiliary verbs but aux_verb_markup is set to FALSE. This may not give ideal results.\n")
    }
    tokens$get_aux_verbs_par = "YES"
    verb_pos = c("VERB", "AUX")
  } else {
    tokens$get_aux_verbs_par = "NO"
    verb_pos = c("VERB")
  }

  ###############################################################################################
  ######################################Rule implementation######################################
  ###############################################################################################

  ###############################################################################################
  ############################################Action#############################################
  ###############################################################################################

  if("a" %in% motif_classes){
    if(verbose){cat("Extracting actions\n")}
    
    ###############################################################################################
    ##### Run fast rules
    tryCatch({
      tokens = semgram:::a_1(tokens, entities, verb_pos, agent_patient_pos)
    }, error = function(e){
      message("There was an error in extracting action motifs (a_1). Some action motifs might not have been extracted properly. This is an important rule and you probably shouldn't proceed.")
      tokens$nsubj_act_conj <<- NA
    })

    ###############################################################################################
    ##### Run slow rules
    if(fast){
      tokens$nsubj_act_noun_conj_verb_conj = 
        tokens$by_act = 
        tokens$by_act_noun_conjunct = 
        tokens$by_act_2 = 
        tokens$by_act_2_1 = 
        tokens$by_act_2_noun_conj = 
        tokens$by_act_2_noun_conj_1 = 
        tokens$xcomp_act_conj_verb = 
        tokens$xcomp_act_conj_noun = NA
      
    } else {
      tryCatch({
        tokens = semgram:::a_2(tokens, entities, verb_pos, agent_patient_pos)
      },error = function(e){
        message("There was an error in extracting action motifs (a_2). Some action motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$nsubj_act_noun_conj_verb_conj <<- NA
      })
      tryCatch({
        tokens = semgram:::a_3(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting action motifs (a_3). Some action motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$by_act <<- NA
      })
      tryCatch({
        tokens = semgram:::a_4(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting action motifs (a_4). Some action motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$by_act_noun_conjunct <<- NA
      })
      tryCatch({
        tokens = semgram:::a_5(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting action motifs (a_5). Some action motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$by_act_2 <<- NA
      })
      tryCatch({
        tokens = semgram:::a_6(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting action motifs (a_6). Some action motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$by_act_2_1 <<- NA
      })
      tryCatch({
        tokens = semgram:::a_7(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting action motifs (a_7). Some action motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$by_act_2_noun_conj <<- NA
      })
      tryCatch({
        tokens = semgram:::a_8(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting action motifs (a_8). Some action motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$by_act_2_noun_conj_1 <<- NA
      })
      tryCatch({
        tokens = semgram:::a_9(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting action motifs (a_9). Some action motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$xcomp_act_conj_verb <<- NA
      })
      tryCatch({
        tokens = semgram:::a_10(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting action motifs (a_10). Some action motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$xcomp_act_conj_noun <<- NA
      })
    }
  }


  ###############################################################################################
  #########################################Patients##############################################
  ###############################################################################################

  if("P" %in% motif_classes){
    if(verbose){cat("Extracting patients\n")}
    ###############################################################################################
    tryCatch({
      tokens = semgram:::P_1(tokens, entities, verb_pos, agent_patient_pos)
    }, error = function(e){
      message("There was an error in extracting Patient motifs (P_1). Some Patient motifs might not have been extracted properly. This is an important rule and you probably shouldn't proceed.")
      tokens$nsubj_obj_conj_act <<- NA
    })

    ###############################################################################################
    if(fast){
      tokens$nsubj_obj_conj = 
        tokens$nsubj_conj_obj_act =
        tokens$nsubj_conj_subj_cons_obj =
        tokens$by_act_obj =
        tokens$by_act_obj_nc =
        tokens$by_act_obj_cverb =
        tokens$by_act_obj_cverb_cobj =
        tokens$xcomp_act_obj =
        tokens$xcomp_act_obj_vconj =
        tokens$xcomp_act_obj_nconj =
        tokens$xcomp_act_obj_nconj_vconj = NA
      
    } else {
      tryCatch({
        tokens = semgram:::P_2(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting Patient motifs (P_2). Some patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$nsubj_obj_conj <<- NA
      })
      tryCatch({
        tokens = semgram:::P_3(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting patient motifs (P_3). Some patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$nsubj_conj_obj_act <<- NA
      })
      tryCatch({
        tokens = semgram:::P_4(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting patient motifs (P_4). Some patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$nsubj_conj_subj_cons_obj <<- NA
      })
      tryCatch({
        tokens = semgram:::P_5(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting patient motifs (P_5). Some patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$by_act_obj <<- NA
      })
      tryCatch({
        tokens = semgram:::P_6(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting patient motifs (P_6). Some patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$by_act_obj_nc <<- NA
      })
      tryCatch({
        tokens = semgram:::P_7(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting patient motifs (P_7). Some patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$by_act_obj_cverb <<- NA
      })
      tryCatch({
        tokens = semgram:::P_8(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting patient motifs (P_8). Some patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$by_act_obj_cverb_cobj <<- NA
      })
      tryCatch({
        tokens = semgram:::P_9(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting patient motifs (P_9). Some patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$xcomp_act_obj <<- NA
      })
      tryCatch({
        tokens = semgram:::P_10(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting patient motifs (P_10). Some patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$xcomp_act_obj_vconj <<- NA
      })
      tryCatch({
        tokens = semgram:::P_11(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting patient motifs (P_11). Some patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$xcomp_act_obj_nconj <<- NA
      })
      tryCatch({
        tokens = semgram:::P_12(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting patient motifs (P_12). Some patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$xcomp_act_obj_nconj_vconj <<- NA
      })
    }
  }


  ###############################################################################################
  #####################################Action & Patients#########################################
  ###############################################################################################

  if("aP" %in% motif_classes){
    if(verbose){cat("Extracting action-patients\n")}
    ###############################################################################################
    tryCatch({
      nsubj_obj_conj_act_aP_casted = semgram:::aP_1(tokens, entities, verb_pos, agent_patient_pos, extract)
    }, error = function(e){
      message("There was an error in extracting action-patient motifs (aP_1). Some action-patient motifs might not have been extracted properly. This is an important rule and you probably shouldn't proceed.")
      nsubj_obj_conj_act_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
    })

    ###############################################################################################
    if(fast){
      nsubj_obj_conj_aP_casted = 
        nsubj_conj_obj_act_aP_casted = 
        nsubj_conj_subj_cons_obj_aP_casted = 
        by_act_obj_aP_casted = 
        by_act_obj_nc_aP_casted = 
        by_act_obj_cverb_1_aP_casted = 
        by_act_obj_cverb_2_aP_casted = 
        by_act_obj_cverb_cobj_1_aP_casted = 
        by_act_obj_cverb_cobj_2_aP_casted = 
        xcomp_act_obj_aP_casted = 
        xcomp_act_obj_vconj_aP_casted = 
        xcomp_act_obj_nconj_aP_casted = 
        xcomp_act_obj_nconj_vconj_aP_casted = data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      
    } else {
      tryCatch({
        nsubj_obj_conj_aP_casted = semgram:::aP_2(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_2). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        nsubj_obj_conj_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      })
      tryCatch({
        nsubj_conj_obj_act_aP_casted = semgram:::aP_3(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_3). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        nsubj_conj_obj_act_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      })
      tryCatch({
        nsubj_conj_subj_cons_obj_aP_casted = semgram:::aP_4(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_4). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        nsubj_conj_subj_cons_obj_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      })
      tryCatch({
        by_act_obj_aP_casted = semgram:::aP_5(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_5). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        by_act_obj_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      })
      tryCatch({
        by_act_obj_nc_aP_casted = semgram:::aP_6(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_6). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        by_act_obj_nc_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      })
      tryCatch({
        by_act_obj_cverb_1_aP_casted = semgram:::aP_7(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_7). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        by_act_obj_cverb_1_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      })
      tryCatch({
        by_act_obj_cverb_2_aP_casted = semgram:::aP_8(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_8). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        by_act_obj_cverb_2_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
        tokens$by_act_obj_cverb_2_aP <<- NA
      })
      tryCatch({
        by_act_obj_cverb_cobj_1_aP_casted = semgram:::aP_9(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_9). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        by_act_obj_cverb_cobj_1_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      })
      tryCatch({
        by_act_obj_cverb_cobj_2_aP_casted = semgram:::aP_10(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_10). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        by_act_obj_cverb_cobj_2_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      })
      tryCatch({
        xcomp_act_obj_aP_casted = semgram:::aP_11(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_11). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        xcomp_act_obj_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      })
      tryCatch({
        xcomp_act_obj_vconj_aP_casted = semgram:::aP_12(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_12). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        xcomp_act_obj_vconj_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      })
      tryCatch({
        xcomp_act_obj_nconj_aP_casted = semgram:::aP_13(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_13). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        xcomp_act_obj_nconj_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      })
      tryCatch({
        xcomp_act_obj_nconj_vconj_aP_casted = semgram:::aP_14(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting action-patient motifs (aP_14). Some action-patient motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        xcomp_act_obj_nconj_vconj_aP_casted <<- data.table(doc_id = character(), ann_id = factor(), act = character(), Patient = character())
      })
    }
  }


  ###############################################################################################
  ########################################Treatments#############################################
  ###############################################################################################
  if("t" %in% motif_classes){
    if(verbose){cat("Extracting treatments\n")}
    tryCatch({
      tokens = semgram:::t_1(tokens, entities, verb_pos, agent_patient_pos)
    }, error = function(e){
      message("There was an error in extracting treatment motifs (t_1). Some treatment motifs might not have been extracted properly. This is an important rule and you probably shouldn't proceed.")
      tokens$dobj_treat <<- NA
    })

    if(fast){
      tokens$dobj_conj_treat = 
        tokens$obj_of_by_act = 
        tokens$obj_of_by_act_nconj = NA
      
    } else {
      tryCatch({
        tokens = semgram:::t_2(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting treatment motifs (t_2). Some treatment motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$dobj_conj_treat <<- NA
      })
      tryCatch({
        tokens = semgram:::t_3(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting treatment motifs (t_3). Some treatment motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$obj_of_by_act <<- NA
      })
      tryCatch({
        tokens = semgram:::t_4(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting treatment motifs (t_4). Some treatment motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$obj_of_by_act_nconj <<- NA
      })
    }
  }

  ###############################################################################################
  ###########################################Agent###############################################
  ###############################################################################################

  if("A" %in% motif_classes){
    if(verbose){cat("Extracting agents\n")}
    ###############################################################################################
    tryCatch({
      tokens = semgram:::agent_1(tokens, entities, verb_pos, agent_patient_pos)
    }, error = function(e){
      message("There was an error in extracting agent motifs  (agent_1). Some agent motifs might not have been extracted properly. This is an important rule and you probably shouldn't proceed.")
      tokens$dobj_treat_actor <<- NA
    })
    tryCatch({
      tokens = semgram:::agent_2(tokens, entities, verb_pos, agent_patient_pos)
    }, error = function(e){
      message("There was an error in extracting agent motifs (agent_2). Some agent motifs might not have been extracted properly. This is an important rule and you probably shouldn't proceed.")
      tokens$dobj_treat_conj_actor <<- NA
    })

    ###############################################################################################
    if(fast){
      tokens$dobj_nconj_treat = NA
      tokens$by_act_agent = NA
      tokens$obj_of_by_act_nconj_ac = NA
      
    } else {
      tryCatch({
        tokens = semgram:::agent_3(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting agent motifs (agent_3). Some agent motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$dobj_nconj_treat <<- NA
      })
      tryCatch({
        tokens = semgram:::agent_4(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting agent motifs (agent_4). Some agent motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$by_act_agent <<- NA
      })
      tryCatch({
        tokens = semgram:::agent_5(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting agent motifs (agent_5). Some agent motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$obj_of_by_act_nconj_ac <<- NA
      })
    }
  }

  ###############################################################################################
  ###################################Agents & Treatments#########################################
  ###############################################################################################
  if("At" %in% motif_classes){
    if(verbose){cat("Extracting agent-treatments\n")}
    ###############################################################################################
    tryCatch({
      dobj_treat_actor_At_casted = semgram:::At_1(tokens, entities, verb_pos, agent_patient_pos, extract)
    }, error = function(e){
      message("There was an error in extracting agent-treatment motifs (At_1). Some agent-treatment motifs might not have been extracted properly. This is an important rule and you probably shouldn't proceed.")
      dobj_treat_actor_At_casted <<- data.table(doc_id = character(), ann_id = factor(), treatment = character(), Agent = character())
    })

    ###############################################################################################
    if(fast){
      dobj_treat_conj_actor_At_casted =
        dobj_nconj_treat_At_casted =
        by_act_agent_At_casted = 
        obj_of_by_act_nconj_ac_At_casted = data.table(doc_id = character(), ann_id = factor(), treatment = character(), Agent = character())
    } else {
      tryCatch({
        dobj_treat_conj_actor_At_casted = semgram:::At_2(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting agent-treatment motifs (At_2). Some agent-treatment motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        dobj_treat_conj_actor_At_casted <<- data.table(doc_id = character(), ann_id = factor(), treatment = character(), Agent = character())
      })
      tryCatch({
        dobj_nconj_treat_At_casted = semgram:::At_3(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting agent-treatment motifs (At_3). Some agent-treatment motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        dobj_nconj_treat_At_casted <<- data.table(doc_id = character(), ann_id = factor(), treatment = character(), Agent = character())
      })
      tryCatch({
        by_act_agent_At_casted = semgram:::At_4(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting agent-treatment motifs (At_4). Some agent-treatment motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        by_act_agent_At_casted <<- data.table(doc_id = character(), ann_id = factor(), treatment = character(), Agent = character())
        tokens$by_act_agent_At <<- NA
      })
      tryCatch({
        obj_of_by_act_nconj_ac_At_casted = semgram:::At_5(tokens, entities, verb_pos, agent_patient_pos, extract)
      }, error = function(e){
        message("There was an error in extracting agent-treatment motifs (At_5). Some agent-treatment motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        obj_of_by_act_nconj_ac_At_casted <<- data.table(doc_id = character(), ann_id = factor(), treatment = character(), Agent = character())
        tokens$obj_of_by_act_nconj_ac_At <<- NA
      })
    }
  }

  ###############################################################################################
  #####################################Characterizations#########################################
  ###############################################################################################

  if("be" %in% motif_classes){
    if(verbose){cat("Extracting characterizations\n")}
    ###############################################################################################
    tryCatch({
      tokens = semgram:::be_1(tokens, entities, verb_pos, agent_patient_pos)
    }, error = function(e){
      message("There was an error in extracting characterization motifs (be_1). Some characterization motifs might not have been extracted properly. This is an important rule and you probably shouldn't proceed.")
      tokens$being_adj <<- NA
    })
    tryCatch({
      tokens = semgram:::be_6(tokens, entities, verb_pos, agent_patient_pos)
    }, error = function(e){
      message("There was an error in extracting characterization motifs (be_6). Some characterization motifs might not have been extracted properly. This is an important rule and you probably shouldn't proceed.")
      tokens$amod_adj <<- NA
    })
    
    ###############################################################################################
    if(fast){
      tokens$being_adj_nconj = 
        tokens$appos_char = 
        tokens$being_adj_vconj = 
        tokens$being_adj_xcomp = NA
    
    } else {
      tryCatch({
        tokens = semgram:::be_2(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting characterization motifs (be_2). Some characterization motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$being_adj_nconj <<- NA
      })
      tryCatch({
        tokens = semgram:::be_3(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting characterization motifs (be_3). Some characterization motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$appos_char <<- NA
      })
      tryCatch({
        tokens = semgram:::be_4(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting characterization motifs (be_4). Some characterization motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$being_adj_vconj <<- NA
      })
      tryCatch({
        tokens = semgram:::be_5(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting characterization motifs (be_5). Some characterization motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$being_adj_xcomp <<- NA
      })
    }


    if(be_entity){
      ###############################################################################################
      tryCatch({
        tokens = semgram:::be_7(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting characterization motifs (be_7). Some characterization motifs might not have been extracted properly. This is an important rule and you probably shouldn't proceed.")
        tokens$being_entity <<- NA
      })

      ###############################################################################################
      if(fast){
        tokens$being_entity_c = NA
      } else {
        tryCatch({
          tokens = semgram:::be_8(tokens, entities, verb_pos, agent_patient_pos)
        }, error = function(e){
          message("There was an error in extracting characterization motifs (be_8). Some characterization motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
          tokens$being_entity_c <<- NA
        })
      }
    } else {
      tokens$being_entity = NA
      tokens$being_entity_c = NA
    }
  }


  ###############################################################################################
  ########################################Posessions#############################################
  ###############################################################################################
  if("H" %in% motif_classes){
    if(verbose){cat("Extracting possessions\n")}
    ###############################################################################################
    tryCatch({
      tokens = semgram:::H_1(tokens, entities, verb_pos, agent_patient_pos)
    }, error = function(e){
      message("There was an error in extracting posession motifs (H_1). Some posession motifs might not have been extracted properly. This is an important rule and you probably shouldn't proceed.")
      tokens$posessive_o <<- NA
    })
    tryCatch({
      tokens = semgram:::H_3(tokens, entities, verb_pos, agent_patient_pos)
    }, error = function(e){
      message("There was an error in extracting possession motifs (H_3). Some possession motifs might not have been extracted properly. This is an important rule and you probably shouldn't proceed.")
      tokens$have_nsubj_obj_conj_act <<- NA
    })

    ###############################################################################################
    if(fast){
      tokens$posessive_of = NA
      tokens$have_nsubj_obj_conj = NA
      tokens$have_nsubj_conj_obj_act = NA
      tokens$have_nsubj_conj_subj_cons_obj = NA
      tokens$have_xcomp_act_obj = NA
      tokens$have_xcomp_act_obj_vconj = NA
      tokens$have_xcomp_act_obj_nconj = NA
      tokens$have_xcomp_act_obj_nconj_vconj = NA
    
    } else {
      tryCatch({
        tokens = semgram:::H_2(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting posession motifs (H_2). Some posession motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$posessive_of <<- NA
      })
      tryCatch({
        tokens = semgram:::H_4(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting possession motifs (H_4). Some possession motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$have_nsubj_obj_conj <<- NA
      })
      tryCatch({
        tokens = semgram:::H_5(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting possession motifs (H_5). Some possession motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$have_nsubj_conj_obj_act <<- NA
      })
      tryCatch({
        tokens = semgram:::H_6(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting possession motifs (H_6). Some possession motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$have_nsubj_conj_subj_cons_obj <<- NA
      })
      tryCatch({
        tokens = semgram:::H_7(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting possession motifs (H_7). Some possession motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$have_xcomp_act_obj <<- NA
      })
      tryCatch({
        tokens = semgram:::H_8(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting possession motifs (H_8). Some possession motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$have_xcomp_act_obj_vconj <<- NA
      })
      tryCatch({
        tokens = semgram:::H_9(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting possession motifs (H_9). Some possession motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$have_xcomp_act_obj_nconj <<- NA
      })
      tryCatch({
        tokens = semgram:::H_10(tokens, entities, verb_pos, agent_patient_pos)
      }, error = function(e){
        message("There was an error in extracting possession motifs (H_10). Some possession motifs might not have been extracted properly. This is a secondary rule and you can probably proceed.")
        tokens$have_xcomp_act_obj_nconj_vconj <<- NA
      })
    }
  }


  ###############################################################################################
  ######################################Lowercase extractions####################################
  ###############################################################################################

  ###############################################################################################
  ##### Lowercase
  if(lowercase){
    tokens$token = tolower(tokens$token)
    tokens$lemma = tolower(tokens$lemma)
  }


  ###############################################################################################
  ###################################Combine the motifs to a list################################
  ###############################################################################################

  ##### Define columns
  act_cols = c("nsubj_act_conj", "nsubj_act_noun_conj_verb_conj",
                "by_act", "by_act_noun_conjunct", "by_act_2", "by_act_2_1", "by_act_2_noun_conj",
                "by_act_2_noun_conj_1", "xcomp_act_conj_verb", "xcomp_act_conj_noun")
  patient_cols = c("nsubj_obj_conj_act","nsubj_obj_conj", "nsubj_conj_obj_act", "nsubj_conj_subj_cons_obj",
                   "by_act_obj", "by_act_obj_nc", "by_act_obj_cverb", "by_act_obj_cverb_cobj", "xcomp_act_obj",
                   "xcomp_act_obj_vconj", "xcomp_act_obj_nconj", "xcomp_act_obj_nconj_vconj")
  treatment_cols = c("dobj_treat", "dobj_conj_treat", "obj_of_by_act", "obj_of_by_act_nconj")
  agent_cols = c("dobj_treat_actor", "dobj_treat_conj_actor", "dobj_nconj_treat", "by_act_agent", "obj_of_by_act_nconj_ac")
  characterization_cols = c("being_adj", "being_adj_nconj", "being_adj_vconj", "being_adj_xcomp", "appos_char", "amod_adj", "being_entity", "being_entity_c")
  possession_cols = c("posessive_o", "posessive_of",
                       "have_nsubj_obj_conj_act", "have_nsubj_obj_conj", "have_nsubj_conj_obj_act",
                       "have_nsubj_conj_subj_cons_obj", "have_xcomp_act_obj",
                       "have_xcomp_act_obj_vconj", "have_xcomp_act_obj_nconj", "have_xcomp_act_obj_nconj_vconj")
  all_cols = c(act_cols, patient_cols, treatment_cols, agent_cols, characterization_cols, possession_cols)
  all_cols = subset(all_cols, all_cols %in% colnames(tokens))

  ##### Transform tokens object
  tokens = semgram:::motif_replace_helper(annotated_tokens = tokens, motif_names = all_cols, extract_p = extract)

  ##### Get motifs
  acts = if("a" %in% motif_classes){unlist(tokens[,..act_cols], use.names = FALSE)} else {NA}
  if(markup){
    acts = if(length(acts[!is.na(acts)]) > 0){paste0("a_", acts[!is.na(acts)])} else {character(0)}
  } else {
    acts = if(length(acts[!is.na(acts)]) > 0){paste0(acts[!is.na(acts)])} else {character(0)}
  }

  patients = if("P" %in% motif_classes){unlist(tokens[,..patient_cols], use.names = FALSE)} else {NA}
  if(markup){
    patients = if(length(patients[!is.na(patients)]) > 0){paste0("P_", patients[!is.na(patients)])} else {character(0)}
  } else {
    patients = if(length(patients[!is.na(patients)]) > 0){paste0(patients[!is.na(patients)])} else {character(0)}
  }

  treatments = if("t" %in% motif_classes){unlist(tokens[,..treatment_cols], use.names = FALSE)} else {NA}
  if(markup){
    treatments = if(length(treatments[!is.na(treatments)]) > 0){paste0("t_", treatments[!is.na(treatments)])} else {character(0)}
  } else {
    treatments = if(length(treatments[!is.na(treatments)]) > 0){paste0(treatments[!is.na(treatments)])} else {character(0)}
  }

  agents = if("A" %in% motif_classes){unlist(tokens[,..agent_cols], use.names = FALSE)} else {NA}
  if(markup){
    agents = if(length(agents[!is.na(agents)]) > 0){paste0("A_", agents[!is.na(agents)])} else {character(0)}
  } else {
    agents = if(length(agents[!is.na(agents)]) > 0){paste0(agents[!is.na(agents)])} else {character(0)}
  }

  characterizations = if("be" %in% motif_classes){unlist(tokens[,..characterization_cols], use.names = FALSE)} else {NA}
  if(markup){
    characterizations = if(length(characterizations[!is.na(characterizations)]) > 0){paste0("be_", characterizations[!is.na(characterizations)])} else {character(0)}
  } else {
    characterizations = if(length(characterizations[!is.na(characterizations)]) > 0){paste0(characterizations[!is.na(characterizations)])} else {character(0)}
  }

  possessions = if("H" %in% motif_classes){unlist(tokens[,..possession_cols], use.names = FALSE)} else {NA}
  if(markup){
    possessions = if(length(possessions[!is.na(possessions)]) > 0){paste0("H_", possessions[!is.na(possessions)])} else {character(0)}
  } else {
    possessions = if(length(possessions[!is.na(possessions)]) > 0){paste0(possessions[!is.na(possessions)])} else {character(0)}
  }


  agent_treatments = if("At" %in% motif_classes){
    agent_treatments = rbind(dobj_treat_actor_At_casted,
                             dobj_treat_conj_actor_At_casted,
                             dobj_nconj_treat_At_casted,
                             by_act_agent_At_casted,
                             obj_of_by_act_nconj_ac_At_casted)
    if(lowercase){
      agent_treatments$treatment = tolower(agent_treatments$treatment)
      agent_treatments$Agent = tolower(agent_treatments$Agent)
    }

    agent_treatments$Agent_split = str_split(agent_treatments$Agent," ")
    if(nrow(agent_treatments)>0){as.vector(unlist(apply(agent_treatments, 1, semgram:::custom_paste_At, markup)))}else{character(0)}
    } else {character(0)}

  action_Patients = if("aP" %in% motif_classes){
    action_Patients = rbind(nsubj_obj_conj_act_aP_casted,
                             nsubj_obj_conj_aP_casted,
                             nsubj_conj_obj_act_aP_casted,
                             nsubj_conj_subj_cons_obj_aP_casted,
                             by_act_obj_aP_casted,
                             by_act_obj_nc_aP_casted,
                             by_act_obj_cverb_1_aP_casted,
                             by_act_obj_cverb_2_aP_casted,
                             by_act_obj_cverb_cobj_1_aP_casted,
                             by_act_obj_cverb_cobj_2_aP_casted,
                             xcomp_act_obj_aP_casted,
                             xcomp_act_obj_vconj_aP_casted,
                             xcomp_act_obj_nconj_aP_casted,
                             xcomp_act_obj_nconj_vconj_aP_casted)
    if(lowercase){
      action_Patients$act = tolower(action_Patients$act)
      action_Patients$Patient = tolower(action_Patients$Patient)
    }
    action_Patients$Patient_split = str_split(action_Patients$Patient," ")
    if(nrow(action_Patients)>0){as.vector(unlist(apply(action_Patients, 1, semgram:::custom_paste_aP, markup)))}else{character(0)}
    } else {character(0)}
  ##### Combine to list object
  motif_list = list("acts" = acts, "patients" = patients, "treatments" = treatments, "agents" = agents,
                    "characterizations" = characterizations, "possessions" = possessions,
                    "agent_treatments" = agent_treatments,
                    "action_Patients" = action_Patients)


  ###############################################################################################
  ###########################################Return##############################################
  ###############################################################################################
  return(motif_list)
}
